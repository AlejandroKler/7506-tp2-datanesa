{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de los df de features para entrenar y predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_18_20 = pd.read_csv(\"windows/18_20/features.csv\") \n",
    "features_19_21 = pd.read_csv(\"windows/19_21/features.csv\")\n",
    "features_20_22 = pd.read_csv(\"windows/20_22/features.csv\")\n",
    "features_21_23 = pd.read_csv(\"windows/21_23/features.csv\")\n",
    "features_24_26 = pd.read_csv(\"windows/24_26/features.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_auc_18_20 = pd.read_csv(\"windows/18_20/labels_auc.csv\")\n",
    "label_auc_19_21 = pd.read_csv(\"windows/19_21/labels_auc.csv\")\n",
    "label_auc_20_22 = pd.read_csv(\"windows/20_22/labels_auc.csv\")\n",
    "label_auc_21_23 = pd.read_csv(\"windows/21_23/labels_auc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_inst_18_20 = pd.read_csv(\"windows/18_20/labels_inst.csv\")\n",
    "label_inst_19_21 = pd.read_csv(\"windows/19_21/labels_inst.csv\")\n",
    "label_inst_20_22 = pd.read_csv(\"windows/20_22/labels_inst.csv\")\n",
    "label_inst_21_23 = pd.read_csv(\"windows/21_23/labels_inst.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_clas_auc_18_20 = pd.DataFrame({'ref_hash': label_auc_18_20['ref_hash'], 'label_auc': label_auc_18_20['label_auc'] == 259200})\n",
    "#labels_clas_auc_19_21 = pd.DataFrame({'ref_hash': label_auc_19_21['ref_hash'], 'label_auc': label_auc_19_21['label_auc'] == 259200})\n",
    "#labels_clas_auc_20_22 = pd.DataFrame({'ref_hash': label_auc_20_22['ref_hash'], 'label_auc': label_auc_20_22['label_auc'] == 259200})\n",
    "#labels_clas_auc_21_23 = pd.DataFrame({'ref_hash': label_auc_21_23['ref_hash'], 'label_auc': label_auc_21_23['label_auc'] == 259200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_clas_inst_18_20 = pd.DataFrame({'ref_hash': label_inst_18_20['ref_hash'], 'label_inst': label_inst_18_20['label_inst'] == 259200})\n",
    "#labels_clas_inst_19_21 = pd.DataFrame({'ref_hash': label_inst_19_21['ref_hash'], 'label_inst': label_inst_19_21['label_inst'] == 259200})\n",
    "#labels_clas_inst_20_22 = pd.DataFrame({'ref_hash': label_inst_20_22['ref_hash'], 'label_inst': label_inst_20_22['label_inst'] == 259200})\n",
    "#labels_clas_inst_21_23 = pd.DataFrame({'ref_hash': label_inst_21_23['ref_hash'], 'label_inst': label_inst_21_23['label_inst'] == 259200})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_submit(params, result):\n",
    "    tiempo = \"time\"\n",
    "    with open(\"historial_submits.txt\",\"a+\") as f:\n",
    "        f.write(\"\\n\"+tiempo+\"|\"+params+\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(modelo, df_features, labels):\n",
    "    df_features = df_features.merge(labels, how=\"left\", left_on=\"ref_hash\", right_on=\"ref_hash\")\n",
    "    df_features.set_index(\"ref_hash\", inplace=True)\n",
    "    X, y = df_features.iloc[:,:-1], df_features.iloc[:,-1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "    modelo.fit(X_train, y_train, eval_metric='rmse')\n",
    "\n",
    "    prediction = modelo.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auc = xgb.XGBRegressor(\n",
    "    #booster='dart',\n",
    "    learning_rate = 0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=8,\n",
    "    gamma=0.22,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    objective='reg:squarederror',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=18.8,\n",
    "    #sample_type='weighted',\n",
    "    #rate_drop=0.1,\n",
    "    #skip_dropout=0.5,\n",
    "    random_state=272\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inst = xgb.XGBRegressor(\n",
    "    #booster='dart',\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=8,\n",
    "    gamma=0.22,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    objective='reg:squarederror',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=18.8,\n",
    "    #sample_type='weighted',\n",
    "    #rate_drop=0.1,\n",
    "    #skip_dropout=0.5,\n",
    "    random_state=272\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba filtrando los tpos máximos (mejor submit hasta ahora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_times(df_features, df_labels, label_name): #al parecer esta funcion mejora mucho las predicciones de auct\n",
    "    df_labels = df_labels.loc[df_labels[label_name] != 259200].set_index('ref_hash')\n",
    "    df_features = df_features.loc[df_features['time_to_reappear'] != 0]\n",
    "    df_features = df_features.set_index('ref_hash').join(df_labels, how = 'inner')\n",
    "    #df_features.drop(columns = [label_name], inplace = True)\n",
    "    df_labels.reset_index(inplace = True)\n",
    "    df_features.reset_index(inplace= True)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auc_18_20 = filter_max_times(features_18_20, label_auc_18_20, \"label_auc\")\n",
    "train_auc_19_21 = filter_max_times(features_19_21, label_auc_19_21, \"label_auc\")\n",
    "train_auc_20_22 = filter_max_times(features_20_22, label_auc_20_22, \"label_auc\")\n",
    "train_auc_21_23 = filter_max_times(features_21_23, label_auc_21_23, \"label_auc\")\n",
    "\n",
    "frames_auc = [train_auc_18_20, train_auc_19_21, train_auc_20_22, train_auc_21_23]\n",
    "trainning_auc_data = pd.concat(frames_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenar(model_auc, trainning_auc_data.iloc[:,:-1], trainning_auc_data[['ref_hash', 'label_auc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inst_18_20 = filter_max_times(features_18_20, label_inst_18_20, \"label_inst\")\n",
    "train_inst_19_21 = filter_max_times(features_19_21, label_inst_19_21, \"label_inst\")\n",
    "train_inst_20_22 = filter_max_times(features_20_22, label_inst_20_22, \"label_inst\")\n",
    "train_inst_21_23 = filter_max_times(features_21_23, label_inst_21_23, \"label_inst\")\n",
    "\n",
    "frames_inst = [train_inst_18_20, train_inst_19_21, train_inst_20_22, train_inst_21_23]\n",
    "trainning_inst_data = pd.concat(frames_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 75121.819979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([126691.945, 136612.77 , 123031.12 , ..., 130459.11 , 125369.02 ,\n",
       "       133843.25 ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenar(model_inst, trainning_inst_data.iloc[:,:-1], trainning_inst_data[['ref_hash', 'label_inst']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensamble de XGBoost con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 78093.335957\n"
     ]
    }
   ],
   "source": [
    "inst_train = trainning_inst_data.set_index('ref_hash')\n",
    "X, y = inst_train.iloc[:,:-1], inst_train[['label_inst']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 100)\n",
    "\n",
    "\n",
    "random_forest_inst = RandomForestRegressor(\n",
    "                           n_estimators=100, \n",
    "                           min_samples_split = 10, \n",
    "                           random_state=100\n",
    "                         )\n",
    "\n",
    "random_forest_inst.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "params = {'objective': 'reg:squarederror',\n",
    "          'eta': 0.3,\n",
    "          'max_depth': 5,\n",
    "          'min_child_weight': 3,\n",
    "          'silent': 1,\n",
    "          'subsample': 0.7,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'seed': 1}\n",
    "\n",
    "num_trees=250\n",
    "xgboost_inst = xgb.train(params, xgb.DMatrix(\n",
    "    X_train, y_train), num_trees)\n",
    "\n",
    "prediction_inst = (random_forest_inst.predict(X_test) +\n",
    "              xgboost_inst.predict(xgb.DMatrix(X_test)))/2\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, prediction_inst))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 63164.487211\n"
     ]
    }
   ],
   "source": [
    "auc_train = trainning_auc_data.set_index('ref_hash').sample(200000)\n",
    "X, y = auc_train.iloc[:,:-1], auc_train[['label_auc']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 100)\n",
    "\n",
    "\n",
    "random_forest_auc = RandomForestRegressor(\n",
    "                           n_estimators=100, \n",
    "                           min_samples_split = 10, \n",
    "                           random_state=100\n",
    "                         )\n",
    "\n",
    "random_forest_auc.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "params = {'objective': 'reg:squarederror',\n",
    "          'eta': 0.3,\n",
    "          'max_depth': 5,\n",
    "          'min_child_weight': 3,\n",
    "          'silent': 1,\n",
    "          'subsample': 0.7,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'seed': 1}\n",
    "\n",
    "num_trees=250\n",
    "xgboost_auc = xgb.train(params, xgb.DMatrix(\n",
    "    X_train, y_train), num_trees)\n",
    "\n",
    "prediction_auc = (random_forest_auc.predict(X_test) +\n",
    "              xgboost_auc.predict(xgb.DMatrix(X_test)))/2\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, prediction_auc))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auctions = (random_forest_auc.predict(features_24_26.set_index('ref_hash'))\\\n",
    "                  + xgboost_auc.predict(xgb.DMatrix(features_24_26.set_index('ref_hash'))))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_installs = (random_forest_inst.predict(features_24_26.set_index('ref_hash'))\\\n",
    "                  + xgboost_inst.predict(xgb.DMatrix(features_24_26.set_index('ref_hash'))))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auctions = model_auc.predict(features_24_26.set_index(\"ref_hash\"))\n",
    "df_preds_auctions = pd.DataFrame({'ref_hash' : features_24_26['ref_hash'], 'obj' : pred_auctions})\n",
    "df_preds_auctions.to_csv(\"auctions_predictions.csv\", index=False) #persistimos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_installs = model_inst.predict(features_24_26.set_index(\"ref_hash\"))\n",
    "df_preds_installs = pd.DataFrame({'ref_hash' : features_24_26['ref_hash'], 'obj' : pred_installs})\n",
    "df_preds_installs.to_csv(\"installs_predictions.csv\", index=False) #persistimos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Feature Importance Auctions Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_21_23.set_index('ref_hash')\n",
    "Y = label_auc_21_23['label_auc']\n",
    "names = X.columns.tolist()\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, Y)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Feature Importance Installs Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_21_23.set_index('ref_hash')\n",
    "Y = label_inst_21_23['label_inst']\n",
    "names = X.columns.tolist()\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, Y)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df(df, name):\n",
    "    df.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las predicciones tendrán seteadas como índice los ref_hash para no perder la referencia\n",
    "No es necesario filtrar los ref_hash y quedarnos solo con los target en las predicciones que obtenemos ya que de eso\n",
    "se encarga la función "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"target_competencia_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit_df(auctions_predictions, installs_predictions, target):\n",
    "    \n",
    "    target = target.set_index('ref_hash')\n",
    "    \n",
    "    auc = auctions_predictions.reset_index()\n",
    "    auc.columns = ['ref_hash','obj']\n",
    "    auc['ref_hash'] = auc['ref_hash'].astype(str) + \"_sc\"\n",
    "    auc = auc.set_index('ref_hash')\n",
    "    \n",
    "    ins = installs_predictions.reset_index()\n",
    "    ins.columns = ['ref_hash','obj']\n",
    "    ins['ref_hash'] = ins['ref_hash'].astype(str) + \"_st\"\n",
    "    ins = ins.set_index('ref_hash')\n",
    "    \n",
    "    frames = [ins,auc]\n",
    "    submit_result = pd.concat(frames).reset_index()\n",
    "    target_list = target.reset_index('ref_hash')['ref_hash'].tolist()\n",
    "    return submit_result.loc[submit_result['ref_hash'].isin(target_list)].sort_values(by = 'ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_sub = create_submit_df(df_preds_auctions.set_index('ref_hash'), df_preds_installs.set_index('ref_hash'), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df(kaggle_sub, \"submit.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

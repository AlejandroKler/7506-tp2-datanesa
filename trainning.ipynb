{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de los df de features para entrenar y predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_18_20 = pd.read_csv(\"windows/18_20/features.csv\") \n",
    "features_19_21 = pd.read_csv(\"windows/19_21/features.csv\")\n",
    "features_20_22 = pd.read_csv(\"windows/20_22/features.csv\")\n",
    "features_21_23 = pd.read_csv(\"windows/21_23/features.csv\")\n",
    "features_24_26 = pd.read_csv(\"windows/24_26/features.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_auc_18_20 = pd.read_csv(\"windows/18_20/labels_auc.csv\")\n",
    "label_auc_19_21 = pd.read_csv(\"windows/19_21/labels_auc.csv\")\n",
    "label_auc_20_22 = pd.read_csv(\"windows/20_22/labels_auc.csv\")\n",
    "label_auc_21_23 = pd.read_csv(\"windows/21_23/labels_auc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_inst_18_20 = pd.read_csv(\"windows/18_20/labels_inst.csv\")\n",
    "label_inst_19_21 = pd.read_csv(\"windows/19_21/labels_inst.csv\")\n",
    "label_inst_20_22 = pd.read_csv(\"windows/20_22/labels_inst.csv\")\n",
    "label_inst_21_23 = pd.read_csv(\"windows/21_23/labels_inst.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_clas_auc_18_20 = pd.DataFrame({'ref_hash': label_auc_18_20['ref_hash'], 'label_auc': label_auc_18_20['label_auc'] == 259200})\n",
    "#labels_clas_auc_19_21 = pd.DataFrame({'ref_hash': label_auc_19_21['ref_hash'], 'label_auc': label_auc_19_21['label_auc'] == 259200})\n",
    "#labels_clas_auc_20_22 = pd.DataFrame({'ref_hash': label_auc_20_22['ref_hash'], 'label_auc': label_auc_20_22['label_auc'] == 259200})\n",
    "#labels_clas_auc_21_23 = pd.DataFrame({'ref_hash': label_auc_21_23['ref_hash'], 'label_auc': label_auc_21_23['label_auc'] == 259200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_clas_inst_18_20 = pd.DataFrame({'ref_hash': label_inst_18_20['ref_hash'], 'label_inst': label_inst_18_20['label_inst'] == 259200})\n",
    "#labels_clas_inst_19_21 = pd.DataFrame({'ref_hash': label_inst_19_21['ref_hash'], 'label_inst': label_inst_19_21['label_inst'] == 259200})\n",
    "#labels_clas_inst_20_22 = pd.DataFrame({'ref_hash': label_inst_20_22['ref_hash'], 'label_inst': label_inst_20_22['label_inst'] == 259200})\n",
    "#labels_clas_inst_21_23 = pd.DataFrame({'ref_hash': label_inst_21_23['ref_hash'], 'label_inst': label_inst_21_23['label_inst'] == 259200})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_submit(params, result):\n",
    "    tiempo = \"time\"\n",
    "    with open(\"historial_submits.txt\",\"a+\") as f:\n",
    "        f.write(\"\\n\"+tiempo+\"|\"+params+\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(modelo, df_features, labels):\n",
    "    df_features = df_features.merge(labels, how=\"left\", left_on=\"ref_hash\", right_on=\"ref_hash\")\n",
    "    df_features.set_index(\"ref_hash\", inplace=True)\n",
    "    X, y = df_features.iloc[:,:-1], df_features.iloc[:,-1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "    modelo.fit(X_train, y_train, eval_metric='rmse')\n",
    "\n",
    "    prediction = modelo.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auc = xgb.XGBRegressor(\n",
    "    #booster='dart',\n",
    "    learning_rate = 0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=8,\n",
    "    gamma=0.22,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    objective='reg:squarederror',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=18.8,\n",
    "    #sample_type='weighted',\n",
    "    #rate_drop=0.1,\n",
    "    #skip_dropout=0.5,\n",
    "    random_state=272\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inst = xgb.XGBRegressor(\n",
    "    #booster='dart',\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=8,\n",
    "    gamma=0.22,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    objective='reg:squarederror',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=18.8,\n",
    "    #sample_type='weighted',\n",
    "    #rate_drop=0.1,\n",
    "    #skip_dropout=0.5,\n",
    "    random_state=272\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba filtrando los tpos máximos (mejor submit hasta ahora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_times(df_features, df_labels, label_name): #al parecer esta funcion mejora mucho las predicciones de auct\n",
    "    df_labels = df_labels.loc[df_labels[label_name] != 259200].set_index('ref_hash')\n",
    "    df_features = df_features.loc[df_features['time_to_reappear'] != 0]\n",
    "    df_features = df_features.set_index('ref_hash').join(df_labels, how = 'inner')\n",
    "    #df_features.drop(columns = [label_name], inplace = True)\n",
    "    df_labels.reset_index(inplace = True)\n",
    "    df_features.reset_index(inplace= True)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auc_18_20 = filter_max_times(features_18_20, label_auc_18_20, \"label_auc\")\n",
    "train_auc_19_21 = filter_max_times(features_19_21, label_auc_19_21, \"label_auc\")\n",
    "train_auc_20_22 = filter_max_times(features_20_22, label_auc_20_22, \"label_auc\")\n",
    "train_auc_21_23 = filter_max_times(features_21_23, label_auc_21_23, \"label_auc\")\n",
    "\n",
    "frames_auc = [train_auc_18_20, train_auc_19_21, train_auc_20_22, train_auc_21_23]\n",
    "trainning_auc_data = pd.concat(frames_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenar(model_auc, trainning_auc_data.iloc[:,:-1], trainning_auc_data[['ref_hash', 'label_auc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inst_18_20 = filter_max_times(features_18_20, label_inst_18_20, \"label_inst\")\n",
    "train_inst_19_21 = filter_max_times(features_19_21, label_inst_19_21, \"label_inst\")\n",
    "train_inst_20_22 = filter_max_times(features_20_22, label_inst_20_22, \"label_inst\")\n",
    "train_inst_21_23 = filter_max_times(features_21_23, label_inst_21_23, \"label_inst\")\n",
    "\n",
    "frames_inst = [train_inst_18_20, train_inst_19_21, train_inst_20_22, train_inst_21_23]\n",
    "trainning_inst_data = pd.concat(frames_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenar(model_inst, trainning_inst_data.iloc[:,:-1], trainning_inst_data[['ref_hash', 'label_inst']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probemos ahora filtrando solo con los ref_hashes q aparecen en el installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_inst(features_installs, df_installs, df_labels):\n",
    "    df_features = features_installs.set_index('ref_hash').join(df_installs[['ref_hash']].set_index('ref_hash'), how = 'inner')\n",
    "    df_features = df_features.join(df_labels.set_index('ref_hash'), how = 'inner')\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs_18_20 = pd.read_csv('windows/18_20/installs.csv')\n",
    "df_installs_19_21 = pd.read_csv('windows/19_21/installs.csv')\n",
    "df_installs_20_22 = pd.read_csv('windows/20_22/installs.csv')\n",
    "df_installs_21_23 = pd.read_csv('windows/21_23/installs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inst_18_20 = filter_inst(features_18_20,df_installs,label_inst_18_20)\n",
    "train_inst_19_21 = filter_inst(features_19_21,df_installs,label_inst_19_21)\n",
    "train_inst_20_22 = filter_inst(features_20_22,df_installs,label_inst_20_22)\n",
    "train_inst_21_23 = filter_inst(features_21_23,df_installs,label_inst_21_23)\n",
    "\n",
    "frames = [train_inst_18_20,train_inst_19_21,train_inst_20_22,train_inst_21_23]\n",
    "trainning_inst_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainning_inst_data_filtered = trainning_inst_data.loc[trainning_inst_data['label_inst'] != 259200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenar(model_inst, trainning_inst_data_filtered.reset_index().iloc[:,:-1],\\\n",
    "         trainning_inst_data_filtered.reset_index()[['ref_hash', 'label_inst']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 61892.609831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9305.05 , 88668.71 , 59408.71 , ..., 18804.32 , 64425.566,\n",
       "       60978.73 ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_auc = trainning_auc_data.sample(100000)\n",
    "entrenar(model_auc, sample_auc.iloc[:,:-1], sample_auc[['ref_hash', 'label_auc']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auctions = model_auc.predict(features_24_26.set_index(\"ref_hash\"))\n",
    "df_preds_auctions = pd.DataFrame({'ref_hash' : features_24_26['ref_hash'], 'obj' : pred_auctions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_installs = model_inst.predict(features_24_26.set_index(\"ref_hash\"))\n",
    "df_preds_installs = pd.DataFrame({'ref_hash' : features_24_26['ref_hash'], 'obj' : pred_installs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Feature Importance Auctions Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_21_23.set_index('ref_hash')\n",
    "Y = label_auc_21_23['label_auc']\n",
    "names = X.columns.tolist()\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, Y)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Feature Importance Installs Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_21_23.set_index('ref_hash')\n",
    "Y = label_inst_21_23['label_inst']\n",
    "names = X.columns.tolist()\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, Y)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df(df, name):\n",
    "    df.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las predicciones tendrán seteadas como índice los ref_hash para no perder la referencia\n",
    "No es necesario filtrar los ref_hash y quedarnos solo con los target en las predicciones que obtenemos ya que de eso\n",
    "se encarga la función "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"target_competencia_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit_df(auctions_predictions, installs_predictions, target):\n",
    "    \n",
    "    target = target.set_index('ref_hash')\n",
    "    \n",
    "    auc = auctions_predictions.reset_index()\n",
    "    auc.columns = ['ref_hash','obj']\n",
    "    auc['ref_hash'] = auc['ref_hash'].astype(str) + \"_sc\"\n",
    "    auc = auc.set_index('ref_hash')\n",
    "    \n",
    "    ins = installs_predictions.reset_index()\n",
    "    ins.columns = ['ref_hash','obj']\n",
    "    ins['ref_hash'] = ins['ref_hash'].astype(str) + \"_st\"\n",
    "    ins = ins.set_index('ref_hash')\n",
    "    \n",
    "    frames = [ins,auc]\n",
    "    submit_result = pd.concat(frames).reset_index()\n",
    "    target_list = target.reset_index('ref_hash')['ref_hash'].tolist()\n",
    "    return submit_result.loc[submit_result['ref_hash'].isin(target_list)].sort_values(by = 'ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_sub = create_submit_df(df_preds_auctions.set_index('ref_hash'), df_preds_installs.set_index('ref_hash'), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df(kaggle_sub, \"submit.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

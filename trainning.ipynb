{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de los df de features para entrenar y predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_18_20 = pd.read_csv(\"windows/18_20/features.csv\") \n",
    "features_19_21 = pd.read_csv(\"windows/19_21/features.csv\")\n",
    "features_20_22 = pd.read_csv(\"windows/20_22/features.csv\")\n",
    "features_21_23 = pd.read_csv(\"windows/21_23/features.csv\")\n",
    "features_24_26 = pd.read_csv(\"windows/24_26/features.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_auc_18_20 = pd.read_csv(\"windows/18_20/labels_auc.csv\")\n",
    "label_auc_19_21 = pd.read_csv(\"windows/19_21/labels_auc.csv\")\n",
    "label_auc_20_22 = pd.read_csv(\"windows/20_22/labels_auc.csv\")\n",
    "label_auc_21_23 = pd.read_csv(\"windows/21_23/labels_auc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_inst_18_20 = pd.read_csv(\"windows/18_20/labels_inst.csv\")\n",
    "label_inst_19_21 = pd.read_csv(\"windows/19_21/labels_inst.csv\")\n",
    "label_inst_20_22 = pd.read_csv(\"windows/20_22/labels_inst.csv\")\n",
    "label_inst_21_23 = pd.read_csv(\"windows/21_23/labels_inst.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_clas_auc_18_20 = pd.DataFrame({'ref_hash': label_auc_18_20['ref_hash'], 'label_auc': label_auc_18_20['label_auc'] == 259200})\n",
    "#labels_clas_auc_19_21 = pd.DataFrame({'ref_hash': label_auc_19_21['ref_hash'], 'label_auc': label_auc_19_21['label_auc'] == 259200})\n",
    "#labels_clas_auc_20_22 = pd.DataFrame({'ref_hash': label_auc_20_22['ref_hash'], 'label_auc': label_auc_20_22['label_auc'] == 259200})\n",
    "#labels_clas_auc_21_23 = pd.DataFrame({'ref_hash': label_auc_21_23['ref_hash'], 'label_auc': label_auc_21_23['label_auc'] == 259200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_clas_inst_18_20 = pd.DataFrame({'ref_hash': label_inst_18_20['ref_hash'], 'label_inst': label_inst_18_20['label_inst'] == 259200})\n",
    "#labels_clas_inst_19_21 = pd.DataFrame({'ref_hash': label_inst_19_21['ref_hash'], 'label_inst': label_inst_19_21['label_inst'] == 259200})\n",
    "#labels_clas_inst_20_22 = pd.DataFrame({'ref_hash': label_inst_20_22['ref_hash'], 'label_inst': label_inst_20_22['label_inst'] == 259200})\n",
    "#labels_clas_inst_21_23 = pd.DataFrame({'ref_hash': label_inst_21_23['ref_hash'], 'label_inst': label_inst_21_23['label_inst'] == 259200})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_submit(params, result):\n",
    "    tiempo = \"time\"\n",
    "    with open(\"historial_submits.txt\",\"a+\") as f:\n",
    "        f.write(\"\\n\"+tiempo+\"|\"+params+\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo(params):\n",
    "    result = None#entrenar(params)\n",
    "    guardar_submit(params, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(model, features, labels, cv_folds=5, early_stopping_rounds=50):\n",
    "    parametros = model.get_xgb_params()\n",
    "    dmatrix = xgb.DMatrix(features.values, label=labels.values)\n",
    "    cvresult = xgb.cv(parametros, dmatrix, num_boost_round=model.get_params()['n_estimators'],\n",
    "                      nfold=cv_folds,metrics='rmse', #verbose_eval=True,\n",
    "                      early_stopping_rounds=early_stopping_rounds)\n",
    "    model.set_params(n_estimators=cvresult.shape[0])\n",
    "    model.fit(features, labels,eval_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(modelo, df_features, labels):\n",
    "    df_features = df_features.merge(labels, how=\"left\", left_on=\"ref_hash\", right_on=\"ref_hash\")\n",
    "    df_features.set_index(\"ref_hash\", inplace=True)\n",
    "    X, y = df_features.iloc[:,:-1], df_features.iloc[:,-1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "    modelo.fit(X_train, y_train, eval_metric='rmse')\n",
    "    #modelfit(modelo, X_train, y_train, early_stopping_rounds=30)\n",
    "\n",
    "    prediction = modelo.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auc = xgb.XGBRegressor(\n",
    "    #booster='dart',\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=8,\n",
    "    gamma=0.22,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    objective='reg:squarederror',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=18.8,\n",
    "    #sample_type='weighted',\n",
    "    #rate_drop=0.1,\n",
    "    #skip_dropout=0.5,\n",
    "    random_state=272\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenar(model_auc, features_18_20, label_auc_18_20)\n",
    "entrenar(model_auc, features_19_21, label_auc_19_21)\n",
    "entrenar(model_auc, features_20_22, label_auc_20_22)\n",
    "entrenar(model_auc, features_21_23, label_auc_21_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inst = xgb.XGBRegressor(\n",
    "    #booster='dart',\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=8,\n",
    "    gamma=0.22,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    objective='reg:squarederror',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=18.8,\n",
    "    #sample_type='weighted',\n",
    "    #rate_drop=0.1,\n",
    "    #skip_dropout=0.5,\n",
    "    random_state=272\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenar(model_inst, features_18_20, label_inst_18_20)\n",
    "entrenar(model_inst, features_19_21, label_inst_19_21)\n",
    "entrenar(model_inst, features_20_22, label_inst_20_22)\n",
    "entrenar(model_inst, features_21_23, label_inst_21_23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba filtrando los tpos máximos (las predicciones, según Kaggle, mejoran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_accum():\n",
    "    #to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_filtering_max_times(df_features, df_labels, label_name, model):\n",
    "    df_label = df_labels.loc[label_inst_18_20[label_name] != 259200].set_index('ref_hash')\n",
    "    df_features = df_features.set_index('ref_hash').join(df_labels, how = 'inner')\n",
    "    df_features.drop(columns = [label_name], inplace = True)\n",
    "    df_label.reset_index(inplace = True)\n",
    "    df_features.reset_index(inplace= True)\n",
    "    train_accum(model, df_features, df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_inst_test_21_23 = label_inst_21_23.loc[label_inst_21_23['label_inst'] != 259200].set_index('ref_hash')\n",
    "features_inst_test_21_23 = features_21_23.set_index('ref_hash').join(label_inst_test_21_23, how = 'inner')\n",
    "features_inst_test_21_23.drop(columns = [\"label_inst\"], inplace = True)\n",
    "label_inst_test_21_23.reset_index(inplace = True)\n",
    "features_inst_test_21_23.reset_index(inplace= True)\n",
    "entrenar(model_inst, features_inst_test_21_23, label_inst_test_21_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_auc_test_21_23 = label_auc_21_23.loc[label_auc_21_23['label_auc'] != 259200].set_index('ref_hash')\n",
    "features_auc_test_21_23 = features_21_23.set_index('ref_hash').join(label_auc_test_21_23, how = 'inner')\n",
    "features_auc_test_21_23.drop(columns = [\"label_auc\"], inplace = True)\n",
    "label_auc_test_21_23.reset_index(inplace = True)\n",
    "features_auc_test_21_23.reset_index(inplace= True)\n",
    "entrenar(model_auc, features_auc_test_21_23, label_auc_test_21_23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auctions = model_auc.predict(features_24_26.set_index(\"ref_hash\"))\n",
    "df_preds_auctions = pd.DataFrame({'ref_hash' : features_24_26['ref_hash'], 'obj' : pred_auctions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_installs = model_inst.predict(features_24_26.set_index(\"ref_hash\"))\n",
    "df_preds_installs = pd.DataFrame({'ref_hash' : features_24_26['ref_hash'], 'obj' : pred_installs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "names = features_21_23.columns\n",
    "rf = RandomForestRegressor(\n",
    "    random_state=123,\n",
    "    n_estimators=400,\n",
    "    min_samples_split=3\n",
    ")\n",
    "rf.fit(features_21_23.set_index('ref_hash').values, label_auc_21_23.set_index('ref_hash').values.ravel())\n",
    "features_importance = np.vstack((names, rf.feature_importances_)).T\n",
    "features_importance = pd.DataFrame(features_importance)\n",
    "features_importance.columns = ['feature', 'importance']\n",
    "features_importance = features_importance.set_index('feature').sort_values(by=['importance'], ascending=False).iloc[::-1]\n",
    "ax = features_importance.plot(kind='barh')\n",
    "ax.set_title(\"Features importance according to Random Forest\")\n",
    "ax.set(xlabel=\"Importance\", ylabel=\"Feature\")\n",
    "plt.figure(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df(df, name):\n",
    "    df.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las predicciones tendrán seteadas como índice los ref_hash para no perder la referencia\n",
    "No es necesario filtrar los ref_hash y quedarnos solo con los target en las predicciones que obtenemos ya que de eso\n",
    "se encarga la función "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"target_competencia_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit_df(auctions_predictions, installs_predictions, target):\n",
    "    \n",
    "    target = target.set_index('ref_hash')\n",
    "    \n",
    "    auc = auctions_predictions.reset_index()\n",
    "    auc.columns = ['ref_hash','obj']\n",
    "    auc['ref_hash'] = auc['ref_hash'].astype(str) + \"_sc\"\n",
    "    auc = auc.set_index('ref_hash')\n",
    "    \n",
    "    ins = installs_predictions.reset_index()\n",
    "    ins.columns = ['ref_hash','obj']\n",
    "    ins['ref_hash'] = ins['ref_hash'].astype(str) + \"_st\"\n",
    "    ins = ins.set_index('ref_hash')\n",
    "    \n",
    "    frames = [ins,auc]\n",
    "    submit_result = pd.concat(frames).reset_index()\n",
    "    target_list = target.reset_index('ref_hash')['ref_hash'].tolist()\n",
    "    return submit_result.loc[submit_result['ref_hash'].isin(target_list)].sort_values(by = 'ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_sub = create_submit_df(df_preds_auctions.set_index('ref_hash'), df_preds_installs.set_index('ref_hash'), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df(kaggle_sub, \"submit.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

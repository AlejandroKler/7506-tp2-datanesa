{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de los df de features para entrenar y predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [\"18_20\",\"19_21\",\"20_22\",\"21_23\"]\n",
    "features = {}\n",
    "label_auc = {}\n",
    "label_inst = {}\n",
    "label_clas_auc = {}\n",
    "label_clas_inst = {}\n",
    "\n",
    "for window in windows:\n",
    "    features[window] = pd.read_csv(\"windows/{}/features.csv\".format(window), index_col=\"ref_hash\")\n",
    "    label_auc[window] = pd.read_csv(\"windows/{}/labels_auc.csv\".format(window), index_col=\"ref_hash\")\n",
    "    label_inst[window] = pd.read_csv(\"windows/{}/labels_inst.csv\".format(window), index_col=\"ref_hash\")\n",
    "    label_clas_auc[window] = pd.DataFrame({'ref_hash': label_auc[window].index, 'label_auc': (label_auc[window]['label_auc'] == 259200).astype(int)}).set_index(\"ref_hash\")\n",
    "    label_clas_inst[window] = pd.DataFrame({'ref_hash': label_inst[window].index, 'label_inst': (label_inst[window]['label_inst'] == 259200).astype(int)}).set_index(\"ref_hash\")\n",
    "    \n",
    "features_to_predict = pd.read_csv(\"windows/24_26/features.csv\", index_col=\"ref_hash\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_submit(params, result):\n",
    "    tiempo = \"time\"\n",
    "    with open(\"historial_submits.txt\",\"a+\") as f:\n",
    "        f.write(\"\\n\"+tiempo+\"|\"+params+\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(modelo, df_features, labels):\n",
    "    df_features = df_features.merge(labels, how=\"left\", left_on=\"ref_hash\", right_on=\"ref_hash\")\n",
    "    df_features.set_index(\"ref_hash\", inplace=True)\n",
    "    X, y = df_features.iloc[:,:-1], df_features.iloc[:,-1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "    \n",
    "    modelo.fit(X_train, y_train, eval_metric='rmse')\n",
    "\n",
    "    prediction = modelo.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(df, feature_list):\n",
    "    return df.reindex(columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list_class_auc = [\n",
    "    'appearances_in_auctions', \n",
    "    'user_appeared_last_day', \n",
    "    'time_to_reappear',\n",
    "    #'amount_of_clicks', \n",
    "    'has_installed', \n",
    "    #'user_clicked_last_day',\n",
    "    'user_installed_last_day', \n",
    "    'amount_of_installs', \n",
    "    #'cant_max_day',\n",
    "    #'cant_min_day', \n",
    "    #'mean_time_to_click', \n",
    "    #'max_time_click',\n",
    "    #'min_time_click', \n",
    "    'mean_auctions_per_day', \n",
    "    'mean_events_per_day',\n",
    "    #'mean_clicks_per_day', \n",
    "    'amount_auctions_in_last_hour',\n",
    "    'amount_auctions_in_last_2_hours', \n",
    "    'amount_auctions_in_last_5_hours',\n",
    "    'amount_auctions_in_last_12_hours', \n",
    "    'amount_auctions_in_last_24_hours',\n",
    "    #'amount_events_in_last_hour', \n",
    "    'amount_events_in_last_2_hours',\n",
    "    'amount_auctions_in_first_hour', \n",
    "    'amount_auctions_in_first_3_hours',\n",
    "    'amount_auctions_in_first_5_hours', \n",
    "    'amount_auctions_in_first_12_hours',\n",
    "    'amount_events_in_first_hour', \n",
    "    'amount_events_in_first_5_hours',\n",
    "    'amount_events_in_first_12_hours', \n",
    "    #'amount_clicks_in_last_2_hours',\n",
    "    #'amount_clicks_in_last_4_hours', \n",
    "    'device_os', \n",
    "    #'std_time_to_click',\n",
    "    'std_time_auctions', \n",
    "    'max_time_install', \n",
    "    'min_time_install',\n",
    "    'mean_time_install', \n",
    "    #'std_time_install', \n",
    "    'max_time_events',\n",
    "    'min_time_events', \n",
    "    'mean_time_events', \n",
    "    'std_time_events',\n",
    "    #'installs_per_events', \n",
    "    #'installs_per_clicks', \n",
    "    'events_x_app_210',\n",
    "    'events_x_app_122', \n",
    "    'events_x_app_65', \n",
    "    'events_x_app_121',\n",
    "    'events_x_app_26', \n",
    "    'most_installed_apps_used', \n",
    "    'cant_apps_used',\n",
    "    #'cant_events_atributed', \n",
    "    #'has_events_atributed',\n",
    "    #'has_events_ids_with_installs', \n",
    "    #'has_events_ids_without_installs',\n",
    "    'cant_events_0_4', \n",
    "    'cant_events_4_8', \n",
    "    'cant_events_8_12',\n",
    "    'cant_events_12_16', \n",
    "    'cant_events_16_20', \n",
    "    'cant_events_20_24',\n",
    "    'cant_auctions_0_4', \n",
    "    'cant_auctions_4_8', \n",
    "    'cant_auctions_8_12',\n",
    "    'cant_auctions_12_16', \n",
    "    'cant_auctions_16_20', \n",
    "    'cant_auctions_20_24',\n",
    "    'implicit', \n",
    "    #'latitude', \n",
    "    #'longitude', \n",
    "    #'clicked_in_last_5_minutes',\n",
    "    #'clicked_with_wifi_in_last_3_hours', \n",
    "    'hour_install', \n",
    "    'hour_events',\n",
    "    #'hour_clicks', \n",
    "    'hour_auctions'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list_class_inst = [\n",
    "    'appearances_in_auctions', \n",
    "    'user_appeared_last_day', \n",
    "    'time_to_reappear',\n",
    "    'amount_of_clicks', \n",
    "    'has_installed', \n",
    "    'user_clicked_last_day',\n",
    "    'user_installed_last_day', \n",
    "    'amount_of_installs', \n",
    "    #'cant_max_day',\n",
    "    #'cant_min_day', \n",
    "    #'mean_time_to_click', \n",
    "    #'max_time_click',\n",
    "    #'min_time_click', \n",
    "    'mean_auctions_per_day', \n",
    "    'mean_events_per_day',\n",
    "    #'mean_clicks_per_day', \n",
    "    'amount_auctions_in_last_hour',\n",
    "    'amount_auctions_in_last_2_hours', \n",
    "    'amount_auctions_in_last_5_hours',\n",
    "    'amount_auctions_in_last_12_hours', \n",
    "    'amount_auctions_in_last_24_hours',\n",
    "    'amount_events_in_last_hour', \n",
    "    'amount_events_in_last_2_hours',\n",
    "    'amount_auctions_in_first_hour', \n",
    "    'amount_auctions_in_first_3_hours',\n",
    "    'amount_auctions_in_first_5_hours', \n",
    "    'amount_auctions_in_first_12_hours',\n",
    "    'amount_events_in_first_hour', \n",
    "    'amount_events_in_first_5_hours',\n",
    "    'amount_events_in_first_12_hours', \n",
    "    #'amount_clicks_in_last_2_hours',\n",
    "    #'amount_clicks_in_last_4_hours', \n",
    "    'device_os', \n",
    "    #'std_time_to_click',\n",
    "    'std_time_auctions', \n",
    "    'max_time_install', \n",
    "    'min_time_install',\n",
    "    'mean_time_install', \n",
    "    'std_time_install', \n",
    "    'max_time_events',\n",
    "    'min_time_events', \n",
    "    'mean_time_events', \n",
    "    'std_time_events',\n",
    "    'installs_per_events', \n",
    "    #'installs_per_clicks', \n",
    "    'events_x_app_210',\n",
    "    'events_x_app_122', \n",
    "    'events_x_app_65', \n",
    "    'events_x_app_121',\n",
    "    'events_x_app_26', \n",
    "    'most_installed_apps_used', \n",
    "    'cant_apps_used',\n",
    "    'cant_events_atributed', \n",
    "    #'has_events_atributed',\n",
    "    #'has_events_ids_with_installs', \n",
    "    'has_events_ids_without_installs',\n",
    "    'cant_events_0_4', \n",
    "    'cant_events_4_8', \n",
    "    'cant_events_8_12',\n",
    "    'cant_events_12_16', \n",
    "    'cant_events_16_20', \n",
    "    'cant_events_20_24',\n",
    "    'cant_auctions_0_4', \n",
    "    'cant_auctions_4_8', \n",
    "    'cant_auctions_8_12',\n",
    "    'cant_auctions_12_16', \n",
    "    'cant_auctions_16_20', \n",
    "    'cant_auctions_20_24',\n",
    "    'implicit', \n",
    "    'latitude', \n",
    "    'longitude', \n",
    "    #'clicked_in_last_5_minutes',\n",
    "    'clicked_with_wifi_in_last_3_hours', \n",
    "    'hour_install', \n",
    "    'hour_events',\n",
    "    'hour_clicks', \n",
    "    'hour_auctions'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_to_train(windows, features, labels, feature_list):\n",
    "    df_list = []\n",
    "    for window in windows:\n",
    "        df = select_features(features[window], feature_list).join(labels[window], how=\"inner\")\n",
    "        df_list.append(df)\n",
    "    df_full = pd.concat(df_list)\n",
    "    df_full.reset_index(inplace=True, drop=True)\n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor = 1 100% balanced\n",
    "# factor = 0 not balanced\n",
    "# label_value label que mas aparece y se debe balancear\n",
    "def balance(df_full, label_name, factor, label_value = 1):\n",
    "    cant_values = df_full[label_name].value_counts()[label_value]\n",
    "    cant_no_values = len(df_full[label_name]) - cant_values\n",
    "    a_borrar = int((cant_values-cant_no_values)*factor)\n",
    "    index_to_drop = np.random.choice(df_full.loc[df_full[label_name] == label_value].index,a_borrar, replace=False)\n",
    "    return df_full.drop(index=index_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(df_full, label_name, test_size=0.3):\n",
    "    y = df_full[label_name]\n",
    "    X_data = df_full.drop(label_name, axis=1)\n",
    "    return train_test_split(X_data, y, test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = features_list_class_inst\n",
    "df_full = get_df_to_train(windows, features, label_clas_inst, features_list)\n",
    "\n",
    "df_full = balance(df_full, \"label_inst\", 1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(df_full, \"label_inst\")\n",
    "\n",
    "model_class_inst = xgb.XGBClassifier()\n",
    "train_model_class = model_class_inst.fit(X_train, y_train)\n",
    "pred_model_class = train_model_class.predict(X_test)\n",
    "print(\"Accuracy for model installs: %.2f\" % (accuracy_score(y_test, pred_model_class) * 100))\n",
    "print(\"Using features: \"+str(features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(pred_model_class).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"label_inst\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = get_df_to_train(windows, features, label_clas_auc, features_list_class_auc)\n",
    "\n",
    "df_full = balance(df_full, \"label_auc\", 1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(df_full, \"label_auc\")\n",
    "\n",
    "model_class_auc = xgb.XGBClassifier()\n",
    "train_model_class = model_class_auc.fit(X_train, y_train)\n",
    "pred_model_class = train_model_class.predict(X_test)\n",
    "print(\"Accuracy for model auctions: %.2f\" % (accuracy_score(y_test, pred_model_class) * 100))\n",
    "print(\"Using features: \"+str(features_list_class_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importancia de los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Importancia de los features de auctions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions_importance = get_df_to_train(windows, features, label_auc, features_list_class_auc)\n",
    "df_auctions_importance = df_auctions_importance.sample(10000)\n",
    "\n",
    "\n",
    "df_auctions_features = df_auctions_importance.drop('label_auc', axis=1)\n",
    "df_auctions_labels = df_auctions_importance['label_auc']\n",
    "\n",
    "X = df_auctions_features.fillna(0)\n",
    "Y = df_auctions_labels\n",
    "names = X.columns.tolist()\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, Y)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Importancia de los features de installs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs_importance = get_df_to_train(windows, features, label_inst, features_list_class_inst)\n",
    "df_installs_importance = df_installs_importance.sample(10000)\n",
    "\n",
    "\n",
    "df_installs_features = df_installs_importance.drop('label_inst', axis=1)\n",
    "df_installs_labels = df_installs_importance['label_inst']\n",
    "\n",
    "X = df_installs_features.fillna(0)\n",
    "Y = df_installs_labels\n",
    "names = X.columns.tolist()\n",
    "rf = RandomForestRegressor(n_estimators=50)\n",
    "rf.fit(X, Y)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de predicción de tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Redes neuronales***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Modelo de redes neuronales de predicción de auctions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_auctions = get_df_to_train(windows, features, label_auc, features_list_class_auc)\n",
    "df_full_auctions = df_full_auctions.fillna(0)\n",
    "\n",
    "# Filtro los tiempos máximos.\n",
    "df_full_auctions = df_full_auctions[df_full_auctions[\"label_auc\"] < 259200]\n",
    "\n",
    "# Separo train y test.\n",
    "X_train_auc, X_test_auc, y_train_auc, y_test_auc = get_train_test_split(df_full_auctions, \"label_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el modelo\n",
    "model_auc_neural = Sequential()\n",
    "\n",
    "# Capa de entrada\n",
    "model_auc_neural.add(Dense(10, input_dim=X_train_auc.shape[1], activation='relu'))\n",
    "\n",
    "# Capa con 30 neuronas\n",
    "model_auc_neural.add(Dense(30, activation='relu'))\n",
    "\n",
    "# Dropout para controlar el overfit\n",
    "model_auc_neural.add(Dropout(0.2))\n",
    "\n",
    "# Capa con 40 neuronas\n",
    "model_auc_neural.add(Dense(40, activation='relu'))\n",
    "\n",
    "# Dropout para controlar el overfit\n",
    "model_auc_neural.add(Dropout(0.2))\n",
    "\n",
    "# Salida del modelo\n",
    "model_auc_neural.add(Dense(1))\n",
    "\n",
    "# Compilo el modelo\n",
    "model_auc_neural.compile(optimizer ='adam', loss = 'mean_squared_error', metrics =[metrics.mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 10)                540       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 30)                330       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 2,151\n",
      "Trainable params: 2,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Veo el modelo\n",
    "model_auc_neural.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entreno el modelo\n",
    "model_auc_neural.fit(X_train_auc, y_train_auc, validation_data=(X_test_auc,y_test_auc), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá pones el valor que da el \"mean_squared_error\" del modelo\n",
    "MSE = 4360503664.0435\n",
    "\n",
    "print(f\"RMSE: {MSE**(1/2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Modelo de redes neuronales de predicción de installs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_inst = get_df_to_train(windows, features, label_inst, features_list_class_inst)\n",
    "df_full_inst = df_full_inst.fillna(0)\n",
    "\n",
    "# Saco los tiempos máximos\n",
    "df_full_inst = df_full_inst[df_full_inst[\"label_inst\"] < 259200]\n",
    "\n",
    "# Separo en train y test\n",
    "X_train_inst, X_test_inst, y_train_inst, y_test_inst = get_train_test_split(df_full_inst, \"label_inst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el modelo\n",
    "model_inst_neural = Sequential()\n",
    "\n",
    "# Capa de entrada\n",
    "model_inst_neural.add(Dense(10, input_dim=X_train_inst.shape[1], activation='relu'))\n",
    "\n",
    "# Capa con 30 neuronas\n",
    "model_inst_neural.add(Dense(40, activation='relu'))\n",
    "\n",
    "# Dropout para controlar el overfit\n",
    "model_inst_neural.add(Dropout(0.4))\n",
    "\n",
    "# Capa con 40 neuronas\n",
    "model_inst_neural.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Dropout para controlar el overfit\n",
    "model_inst_neural.add(Dropout(0.4))\n",
    "\n",
    "# Salida del modelo\n",
    "model_inst_neural.add(Dense(1))\n",
    "\n",
    "# Compilo el modelo\n",
    "model_inst_neural.compile(optimizer ='adam', loss = 'mean_squared_error', metrics =[metrics.mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 40)                440       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 50)                2050      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,191\n",
      "Trainable params: 3,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Veo el modelo\n",
    "model_inst_neural.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entreno el modelo\n",
    "model_inst_neural.fit(X_train_inst, y_train_inst, validation_data=(X_test_inst,y_test_inst), epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá pones el valor que da el \"mean_squared_error\" del modelo\n",
    "MSE = 6556917330.7763\n",
    "\n",
    "print(f\"RMSE: {MSE**(1/2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***XGBoost***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Modelo de XGBoost de predicción de auctions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = get_df_to_train(windows, features, label_auc, features_list_class_auc)\n",
    "\n",
    "df_full = df_full.sample(int(len(df_full)))\n",
    "\n",
    "#df_full = balance(df_full, \"label_auc\", 0, 259200)\n",
    "\n",
    "df_full = df_full.loc[df_full[\"label_auc\"] != 259200]\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(df_full, \"label_auc\", 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auc = xgb.XGBRegressor(   \n",
    "    gamma=0.1, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=4,  \n",
    "    n_estimators=600,\n",
    "    n_jobs=4,  \n",
    "    objective='reg:linear',   \n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_auc.fit(X_train, y_train, eval_metric='rmse')\n",
    "#cv = xgb.cv(params, xg_train, 5000, nfold=n_folds, early_stopping_rounds=early_stopping, verbose_eval=1)\n",
    "prediction = model_auc.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### ***Mejor modelo de auctions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE: 63345.641573\n",
    "CPU times: user 25min 48s, sys: 8.65 s, total: 25min 57s\n",
    "Wall time: 26min 8s\n",
    "    \n",
    "model_auc = xgb.XGBRegressor(\n",
    "    base_score=0.5, \n",
    "    booster='gbtree', \n",
    "    colsample_bylevel=1,\n",
    "    colsample_bytree=1, \n",
    "    gamma=0.1, \n",
    "    learning_rate=0.1, \n",
    "    max_delta_step=0,\n",
    "    max_depth=4, \n",
    "    min_child_weight=1, \n",
    "    missing=None, \n",
    "    n_estimators=600,\n",
    "    n_jobs=1, \n",
    "    nthread=None, \n",
    "    objective='reg:linear', \n",
    "    random_state=0,\n",
    "    reg_alpha=0, \n",
    "    reg_lambda=1, \n",
    "    scale_pos_weight=1, \n",
    "    seed=None,\n",
    "    silent=True, \n",
    "    subsample=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_importance(model_auc, height=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance, plot_tree\n",
    "_ = plot_importance(model_auc, height=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Modelo de XGBoost de predicción de installs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_installs = get_df_to_train(windows, features, label_inst, features_list_class_inst)\n",
    "\n",
    "df_full_installs = df_full_installs.sample(int(len(df_full_installs)*0.5))\n",
    "\n",
    "df_full_installs = balance(df_full_installs, \"label_inst\", 1, 259200)\n",
    "#df_full_installs = df_full_installs[df_full_installs[\"label_inst\"] != 259200]\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(df_full_installs, \"label_inst\", 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inst = xgb.XGBRegressor(\n",
    "    learning_rate = 0.1,\n",
    "    n_estimators=500,\n",
    "    max_dept=5,\n",
    "    gamma=0.1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_inst.fit(X_train, y_train, eval_metric='rmse', verbose=True)\n",
    "\n",
    "prediction = model_inst.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance, plot_tree\n",
    "_ = plot_importance(model_inst, height=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### ***Mejor modelo de installs***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "RMSE: 76768.119164\n",
    "CPU times: user 5min 39s, sys: 2 s, total: 5min 41s\n",
    "Wall time: 5min 44s\n",
    "\n",
    "model_inst = xgb.XGBRegressor(\n",
    "    learning_rate = 0.1,\n",
    "    n_estimators=700,\n",
    "    max_dept=5,\n",
    "    gamma=0.1,\n",
    "    n_jobs=-1\n",
    ")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción auctions XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auctions = model_auc.predict(select_features(features_to_predict, features_list_class_auc))\n",
    "df_preds_auctions = pd.DataFrame({'ref_hash' : features_to_predict.index, 'obj' : pred_auctions})\n",
    "#df_preds_auctions.to_csv(\"auctions_predictions.csv\", index=False) #persistimos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción auctions Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auctions_neural = model_auc_neural.predict(select_features(features_to_predict, features_list_class_auc).fillna(0))\n",
    "pred_auctions_neural = np.array(pred_auctions_neural).flatten()\n",
    "df_preds_auctions_neural = pd.DataFrame({'ref_hash' : features_to_predict.index, 'obj' : pred_auctions_neural})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción installs XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_installs = model_inst.predict(select_features(features_to_predict, features_list_class_inst))\n",
    "df_preds_installs = pd.DataFrame({'ref_hash' : features_to_predict.index, 'obj' : pred_installs})\n",
    "#df_preds_installs.to_csv(\"installs_predictions.csv\", index=False) #persistimos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción installs Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_installs_neural = model_inst_neural.predict(select_features(features_to_predict, features_list_class_inst).fillna(0))\n",
    "pred_installs_neural = np.array(pred_installs_neural).flatten()\n",
    "df_preds_installs_neural = pd.DataFrame({'ref_hash' : features_to_predict.index, 'obj' : pred_installs_neural})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clas_inst = model_class_inst.predict(features_to_predict)\n",
    "\n",
    "df_preds_installs = pd.DataFrame({\"ref_hash\":features_to_predict.index,\"obj\":pred_clas_inst})\n",
    "ref_not_to_predict = []#df_preds_installs.loc[df_preds_installs[\"obj\"] == 1][\"ref_hash\"].unique()\n",
    "\n",
    "df_to_predict = features_to_predict.drop(index=ref_to_predict)\n",
    "\n",
    "pred_installs = model_inst.predict(df_to_predict.reset_index(drop=True))\n",
    "\n",
    "df_pred_value = pd.DataFrame({\"ref_hash\":df_to_predict.index,\"value\":pred_installs})\n",
    "\n",
    "df_preds_installs = df_preds_installs.merge(df_pred_value,left_on=\"ref_hash\",right_on=\"ref_hash\",how=\"left\")\n",
    "df_preds_installs[\"obj\"] = df_preds_installs[\"value\"]\n",
    "del df_preds_installs[\"value\"]\n",
    "df_preds_installs = df_preds_installs.fillna(259200)\n",
    "\n",
    "df_preds_installs.to_csv(\"installs_predictions.csv\", index=False) #persistimos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = get_df_to_train(windows, features, label_auc, features_list_class_auc)\n",
    "df_full = df_full.sample(int(len(df_full)*0.1))\n",
    "df_full = df_full[df_full[\"label_auc\"] != 259200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_depth and min_child_weight tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring= 'neg_mean_squared_error', n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(df_full[features_list_class_auc],df_full['label_auc'])\n",
    "#gsearch1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch1.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Refinamos la búsqueda entre valores acotados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth': [3,4,5],\n",
    " 'min_child_weight': [3,4,5]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBRegressor(learning_rate =0.01, n_estimators=1000, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring= 'neg_mean_squared_error', n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(df_full[features_list_class_auc],df_full['label_auc'])\n",
    "#gsearch2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch2.best_params_  #los mejores parámetros son max_depth 4 y min child_weight 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch2.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and n_estimators tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    "    'n_estimators' : [100,200,500, 1000],\n",
    "    'learning_rate' : [0.1, 0.05, 0.01]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBRegressor(learning_rate =0.1, n_estimators=140, max_depth=3,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test3, scoring= 'neg_mean_squared_error', n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(df_full[features_list_class_auc],df_full['label_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch3.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBRegressor(learning_rate =0.1, n_estimators=200, max_depth=4,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test4, scoring= 'neg_mean_squared_error', n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(df_full[features_list_class_auc],df_full['label_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch4.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample and colsample_bytree tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBRegressor( learning_rate = 0.1, n_estimators=200, max_depth=4,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(df_full[features_list_class_auc],df_full['label_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch5.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBRegressor( learning_rate = 0.1, n_estimators=200, max_depth=4,\n",
    " min_child_weight=3, gamma=0, subsample=0.9, colsample_bytree=0.7,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(df_full[features_list_class_auc],df_full['label_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch6.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df(df, name):\n",
    "    df.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las predicciones tendrán seteadas como índice los ref_hash para no perder la referencia\n",
    "No es necesario filtrar los ref_hash y quedarnos solo con los target en las predicciones que obtenemos ya que de eso\n",
    "se encarga la función "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"target_competencia_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_preds_installs = pd.read_csv(\"installs_predictions.csv\")\n",
    "#df_preds_auctions = pd.read_csv(\"auctions_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit_df(auctions_predictions, installs_predictions, target):\n",
    "    \n",
    "    target = target.set_index('ref_hash')\n",
    "    \n",
    "    auc = auctions_predictions.reset_index()\n",
    "    auc.columns = ['ref_hash','obj']\n",
    "    auc['ref_hash'] = auc['ref_hash'].astype(str) + \"_st\"\n",
    "    auc = auc.set_index('ref_hash')\n",
    "    \n",
    "    ins = installs_predictions.reset_index()\n",
    "    ins.columns = ['ref_hash','obj']\n",
    "    ins['ref_hash'] = ins['ref_hash'].astype(str) + \"_sc\"\n",
    "    ins = ins.set_index('ref_hash')\n",
    "    \n",
    "    frames = [ins,auc]\n",
    "    submit_result = pd.concat(frames).reset_index()\n",
    "    target_list = target.reset_index('ref_hash')['ref_hash'].tolist()\n",
    "    return submit_result.loc[submit_result['ref_hash'].isin(target_list)].sort_values(by = 'ref_hash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_sub = create_submit_df(df_preds_auctions.set_index('ref_hash'), \\\n",
    "                              df_preds_installs.set_index('ref_hash'), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df(kaggle_sub, \"submit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_sub_neural = create_submit_df(df_preds_auctions_neural.set_index('ref_hash'), \\\n",
    "                              df_preds_installs_neural.set_index('ref_hash'), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df(kaggle_sub_neural, \"submit_neural.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de los df de features para entrenar y predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [\"18_20\",\"19_21\",\"20_22\",\"21_23\"]\n",
    "features = {}\n",
    "label_auc = {}\n",
    "label_inst = {}\n",
    "label_clas_auc = {}\n",
    "label_clas_inst = {}\n",
    "\n",
    "for window in windows:\n",
    "    features[window] = pd.read_csv(\"windows/{}/features.csv\".format(window), index_col=\"ref_hash\")\n",
    "    label_auc[window] = pd.read_csv(\"windows/{}/labels_auc.csv\".format(window), index_col=\"ref_hash\")\n",
    "    label_inst[window] = pd.read_csv(\"windows/{}/labels_inst.csv\".format(window), index_col=\"ref_hash\")\n",
    "    label_clas_auc[window] = pd.DataFrame({'ref_hash': label_auc[window].index, 'label_auc': (label_auc[window]['label_auc'] == 259200).astype(int)}).set_index(\"ref_hash\")\n",
    "    label_clas_inst[window] = pd.DataFrame({'ref_hash': label_inst[window].index, 'label_inst': (label_inst[window]['label_inst'] == 259200).astype(int)}).set_index(\"ref_hash\")\n",
    "    \n",
    "features_to_predict = pd.read_csv(\"windows/24_26/features.csv\", index_col=\"ref_hash\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_submit(params, result):\n",
    "    tiempo = \"time\"\n",
    "    with open(\"historial_submits.txt\",\"a+\") as f:\n",
    "        f.write(\"\\n\"+tiempo+\"|\"+params+\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(modelo, df_features, labels):\n",
    "    df_features = df_features.merge(labels, how=\"left\", left_on=\"ref_hash\", right_on=\"ref_hash\")\n",
    "    df_features.set_index(\"ref_hash\", inplace=True)\n",
    "    X, y = df_features.iloc[:,:-1], df_features.iloc[:,-1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "    \n",
    "    modelo.fit(X_train, y_train, eval_metric='rmse')\n",
    "\n",
    "    prediction = modelo.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(df, feature_list):\n",
    "    return df.reindex(columns=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list_class_auc = [\n",
    "    'appearances_in_auctions', \n",
    "    'user_appeared_last_day', \n",
    "    'time_to_reappear',\n",
    "    #'amount_of_clicks', \n",
    "    'has_installed', \n",
    "    #'user_clicked_last_day',\n",
    "    'user_installed_last_day', \n",
    "    'amount_of_installs', \n",
    "    #'cant_max_day',\n",
    "    #'cant_min_day', \n",
    "    #'mean_time_to_click', \n",
    "    #'max_time_click',\n",
    "    #'min_time_click', \n",
    "    'mean_auctions_per_day', \n",
    "    'mean_events_per_day',\n",
    "    #'mean_clicks_per_day', \n",
    "    'amount_auctions_in_last_hour',\n",
    "    'amount_auctions_in_last_2_hours', \n",
    "    'amount_auctions_in_last_5_hours',\n",
    "    'amount_auctions_in_last_12_hours', \n",
    "    'amount_auctions_in_last_24_hours',\n",
    "    #'amount_events_in_last_hour', \n",
    "    'amount_events_in_last_2_hours',\n",
    "    'amount_auctions_in_first_hour', \n",
    "    'amount_auctions_in_first_3_hours',\n",
    "    'amount_auctions_in_first_5_hours', \n",
    "    'amount_auctions_in_first_12_hours',\n",
    "    'amount_events_in_first_hour', \n",
    "    'amount_events_in_first_5_hours',\n",
    "    'amount_events_in_first_12_hours', \n",
    "    #'amount_clicks_in_last_2_hours',\n",
    "    #'amount_clicks_in_last_4_hours', \n",
    "    'device_os', \n",
    "    #'std_time_to_click',\n",
    "    'std_time_auctions', \n",
    "    'max_time_install', \n",
    "    'min_time_install',\n",
    "    'mean_time_install', \n",
    "    #'std_time_install', \n",
    "    'max_time_events',\n",
    "    'min_time_events', \n",
    "    'mean_time_events', \n",
    "    'std_time_events',\n",
    "    #'installs_per_events', \n",
    "    #'installs_per_clicks', \n",
    "    'events_x_app_210',\n",
    "    'events_x_app_122', \n",
    "    'events_x_app_65', \n",
    "    'events_x_app_121',\n",
    "    'events_x_app_26', \n",
    "    'most_installed_apps_used', \n",
    "    'cant_apps_used',\n",
    "    #'cant_events_atributed', \n",
    "    #'has_events_atributed',\n",
    "    #'has_events_ids_with_installs', \n",
    "    #'has_events_ids_without_installs',\n",
    "    'cant_events_0_4', \n",
    "    'cant_events_4_8', \n",
    "    'cant_events_8_12',\n",
    "    'cant_events_12_16', \n",
    "    'cant_events_16_20', \n",
    "    'cant_events_20_24',\n",
    "    'cant_auctions_0_4', \n",
    "    'cant_auctions_4_8', \n",
    "    'cant_auctions_8_12',\n",
    "    'cant_auctions_12_16', \n",
    "    'cant_auctions_16_20', \n",
    "    'cant_auctions_20_24',\n",
    "    'implicit', \n",
    "    #'latitude', \n",
    "    #'longitude', \n",
    "    #'clicked_in_last_5_minutes',\n",
    "    #'clicked_with_wifi_in_last_3_hours', \n",
    "    'hour_install', \n",
    "    'hour_events',\n",
    "    #'hour_clicks', \n",
    "    'hour_auctions'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list_class_inst = [\n",
    "    'appearances_in_auctions', \n",
    "    'user_appeared_last_day', \n",
    "    'time_to_reappear',\n",
    "    'amount_of_clicks', \n",
    "    'has_installed', \n",
    "    'user_clicked_last_day',\n",
    "    'user_installed_last_day', \n",
    "    'amount_of_installs', \n",
    "    #'cant_max_day',\n",
    "    #'cant_min_day', \n",
    "    #'mean_time_to_click', \n",
    "    #'max_time_click',\n",
    "    #'min_time_click', \n",
    "    'mean_auctions_per_day', \n",
    "    'mean_events_per_day',\n",
    "    #'mean_clicks_per_day', \n",
    "    'amount_auctions_in_last_hour',\n",
    "    'amount_auctions_in_last_2_hours', \n",
    "    'amount_auctions_in_last_5_hours',\n",
    "    'amount_auctions_in_last_12_hours', \n",
    "    'amount_auctions_in_last_24_hours',\n",
    "    'amount_events_in_last_hour', \n",
    "    'amount_events_in_last_2_hours',\n",
    "    'amount_auctions_in_first_hour', \n",
    "    'amount_auctions_in_first_3_hours',\n",
    "    'amount_auctions_in_first_5_hours', \n",
    "    'amount_auctions_in_first_12_hours',\n",
    "    'amount_events_in_first_hour', \n",
    "    'amount_events_in_first_5_hours',\n",
    "    'amount_events_in_first_12_hours', \n",
    "    #'amount_clicks_in_last_2_hours',\n",
    "    #'amount_clicks_in_last_4_hours', \n",
    "    'device_os', \n",
    "    #'std_time_to_click',\n",
    "    'std_time_auctions', \n",
    "    'max_time_install', \n",
    "    'min_time_install',\n",
    "    'mean_time_install', \n",
    "    'std_time_install', \n",
    "    'max_time_events',\n",
    "    'min_time_events', \n",
    "    'mean_time_events', \n",
    "    'std_time_events',\n",
    "    'installs_per_events', \n",
    "    #'installs_per_clicks', \n",
    "    'events_x_app_210',\n",
    "    'events_x_app_122', \n",
    "    'events_x_app_65', \n",
    "    'events_x_app_121',\n",
    "    'events_x_app_26', \n",
    "    'most_installed_apps_used', \n",
    "    'cant_apps_used',\n",
    "    'cant_events_atributed', \n",
    "    #'has_events_atributed',\n",
    "    #'has_events_ids_with_installs', \n",
    "    'has_events_ids_without_installs',\n",
    "    'cant_events_0_4', \n",
    "    'cant_events_4_8', \n",
    "    'cant_events_8_12',\n",
    "    'cant_events_12_16', \n",
    "    'cant_events_16_20', \n",
    "    'cant_events_20_24',\n",
    "    'cant_auctions_0_4', \n",
    "    'cant_auctions_4_8', \n",
    "    'cant_auctions_8_12',\n",
    "    'cant_auctions_12_16', \n",
    "    'cant_auctions_16_20', \n",
    "    'cant_auctions_20_24',\n",
    "    'implicit', \n",
    "    'latitude', \n",
    "    'longitude', \n",
    "    #'clicked_in_last_5_minutes',\n",
    "    'clicked_with_wifi_in_last_3_hours', \n",
    "    'hour_install', \n",
    "    'hour_events',\n",
    "    'hour_clicks', \n",
    "    'hour_auctions'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_to_train(windows, features, labels, feature_list):\n",
    "    df_list = []\n",
    "    for window in windows:\n",
    "        df = select_features(features[window], feature_list).join(labels[window], how=\"inner\")\n",
    "        df_list.append(df)\n",
    "    df_full = pd.concat(df_list)\n",
    "    df_full.reset_index(inplace=True, drop=True)\n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor = 1 100% balanced\n",
    "# factor = 0 not balanced\n",
    "# label_value label que mas aparece y se debe balancear\n",
    "def balance(df_full, label_name, factor, label_value = 1):\n",
    "    cant_values = df_full[label_name].value_counts()[label_value]\n",
    "    cant_no_values = len(df_full[label_name]) - cant_values\n",
    "    a_borrar = int((cant_values-cant_no_values)*factor)\n",
    "    index_to_drop = np.random.choice(df_full.loc[df_full[label_name] == label_value].index,a_borrar, replace=False)\n",
    "    return df_full.drop(index=index_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(df_full, label_name, test_size=0.3):\n",
    "    y = df_full[label_name]\n",
    "    X_data = df_full.drop(label_name, axis=1)\n",
    "    return train_test_split(X_data, y, test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = features_list_class_inst\n",
    "df_full = get_df_to_train(windows, features, label_clas_inst, features_list)\n",
    "\n",
    "df_full = balance(df_full, \"label_inst\", 1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(df_full, \"label_inst\")\n",
    "\n",
    "model_class_inst = xgb.XGBClassifier()\n",
    "train_model_class = model_class_inst.fit(X_train, y_train)\n",
    "pred_model_class = train_model_class.predict(X_test)\n",
    "print(\"Accuracy for model installs: %.2f\" % (accuracy_score(y_test, pred_model_class) * 100))\n",
    "print(\"Using features: \"+str(features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(pred_model_class).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"label_inst\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = get_df_to_train(windows, features, label_clas_auc, features_list_class_auc)\n",
    "\n",
    "df_full = balance(df_full, \"label_auc\", 1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(df_full, \"label_auc\")\n",
    "\n",
    "model_class_auc = xgb.XGBClassifier()\n",
    "train_model_class = model_class_auc.fit(X_train, y_train)\n",
    "pred_model_class = train_model_class.predict(X_test)\n",
    "print(\"Accuracy for model auctions: %.2f\" % (accuracy_score(y_test, pred_model_class) * 100))\n",
    "print(\"Using features: \"+str(features_list_class_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importancia de los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Importancia de los features de auctions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions_importance = get_df_to_train(windows, features, label_auc, features_list_class_auc)\n",
    "df_auctions_importance = df_auctions_importance.sample(10000)\n",
    "\n",
    "\n",
    "df_auctions_features = df_auctions_importance.drop('label_auc', axis=1)\n",
    "df_auctions_labels = df_auctions_importance['label_auc']\n",
    "\n",
    "X = df_auctions_features.fillna(0)\n",
    "Y = df_auctions_labels\n",
    "names = X.columns.tolist()\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, Y)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Importancia de los features de installs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs_importance = get_df_to_train(windows, features, label_inst, features_list_class_inst)\n",
    "df_installs_importance = df_installs_importance.sample(10000)\n",
    "\n",
    "\n",
    "df_installs_features = df_installs_importance.drop('label_inst', axis=1)\n",
    "df_installs_labels = df_installs_importance['label_inst']\n",
    "\n",
    "X = df_installs_features.fillna(0)\n",
    "Y = df_installs_labels\n",
    "names = X.columns.tolist()\n",
    "rf = RandomForestRegressor(n_estimators=50)\n",
    "rf.fit(X, Y)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de predicción de tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Redes neuronales***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Modelo de redes neuronales de predicción de auctions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_auctions = get_df_to_train(windows, features, label_auc, features_list_class_auc)\n",
    "df_full_auctions = df_full_auctions.fillna(0)\n",
    "\n",
    "# Filtro los tiempos máximos.\n",
    "df_full_auctions = df_full_auctions[df_full_auctions[\"label_auc\"] < 259200]\n",
    "\n",
    "# Separo train y test.\n",
    "X_train_auc, X_test_auc, y_train_auc, y_test_auc = get_train_test_split(df_full_auctions, \"label_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el modelo\n",
    "model_auc_neural = Sequential()\n",
    "\n",
    "# Capa de entrada\n",
    "model_auc_neural.add(Dense(10, input_dim=X_train_auc.shape[1], activation='relu'))\n",
    "\n",
    "# Capa con 30 neuronas\n",
    "model_auc_neural.add(Dense(30, activation='relu'))\n",
    "\n",
    "# Dropout para controlar el overfit\n",
    "model_auc_neural.add(Dropout(0.4))\n",
    "\n",
    "# Capa con 40 neuronas\n",
    "model_auc_neural.add(Dense(40, activation='relu'))\n",
    "\n",
    "# Dropout para controlar el overfit\n",
    "model_auc_neural.add(Dropout(0.4))\n",
    "\n",
    "# Salida del modelo\n",
    "model_auc_neural.add(Dense(1))\n",
    "\n",
    "# Compilo el modelo\n",
    "model_auc_neural.compile(optimizer ='adam', loss = 'mean_squared_error', metrics =[metrics.mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 10)                540       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                330       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 2,151\n",
      "Trainable params: 2,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Veo el modelo\n",
    "model_auc_neural.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 704627 samples, validate on 301984 samples\n",
      "Epoch 1/20\n",
      "704627/704627 [==============================] - 33s 47us/step - loss: 6245812781.7091 - mean_squared_error: 6245812781.7091 - val_loss: 5279871348.0911 - val_mean_squared_error: 5279871348.0911\n",
      "Epoch 2/20\n",
      "704627/704627 [==============================] - 33s 46us/step - loss: 5369605092.9790 - mean_squared_error: 5369605092.9790 - val_loss: 5612559574.7394 - val_mean_squared_error: 5612559574.7394\n",
      "Epoch 3/20\n",
      "704627/704627 [==============================] - 33s 47us/step - loss: 4992302673.4271 - mean_squared_error: 4992302673.4271 - val_loss: 4648739932.5447 - val_mean_squared_error: 4648739932.5447\n",
      "Epoch 4/20\n",
      "704627/704627 [==============================] - 33s 47us/step - loss: 4831666088.1001 - mean_squared_error: 4831666088.1001 - val_loss: 4687523287.9941 - val_mean_squared_error: 4687523287.9941\n",
      "Epoch 5/20\n",
      "704627/704627 [==============================] - 34s 48us/step - loss: 4772368779.4696 - mean_squared_error: 4772368779.4696 - val_loss: 4579655949.5433 - val_mean_squared_error: 4579655949.5433\n",
      "Epoch 6/20\n",
      "704627/704627 [==============================] - 34s 48us/step - loss: 4724135549.3611 - mean_squared_error: 4724135549.3611 - val_loss: 4836386084.6489 - val_mean_squared_error: 4836386084.6489\n",
      "Epoch 7/20\n",
      "704627/704627 [==============================] - 34s 49us/step - loss: 4709091222.7476 - mean_squared_error: 4709091222.7476 - val_loss: 4404887908.7371 - val_mean_squared_error: 4404887908.7371\n",
      "Epoch 8/20\n",
      "704627/704627 [==============================] - 34s 48us/step - loss: 4678439277.9886 - mean_squared_error: 4678439277.9886 - val_loss: 4743092175.3947 - val_mean_squared_error: 4743092175.3947\n",
      "Epoch 9/20\n",
      "704627/704627 [==============================] - 34s 48us/step - loss: 4637386589.3238 - mean_squared_error: 4637386589.3238 - val_loss: 4484891631.5473 - val_mean_squared_error: 4484891631.5473\n",
      "Epoch 10/20\n",
      "704627/704627 [==============================] - 35s 49us/step - loss: 4601813777.7736 - mean_squared_error: 4601813777.7736 - val_loss: 4574404894.6267 - val_mean_squared_error: 4574404894.6267\n",
      "Epoch 11/20\n",
      "704627/704627 [==============================] - 33s 47us/step - loss: 4550875567.6548 - mean_squared_error: 4550875567.6548 - val_loss: 4488376061.7281 - val_mean_squared_error: 4488376061.7281\n",
      "Epoch 12/20\n",
      "704627/704627 [==============================] - 33s 46us/step - loss: 4518304241.9347 - mean_squared_error: 4518304241.9347 - val_loss: 4394487998.1011 - val_mean_squared_error: 4394487998.1011\n",
      "Epoch 13/20\n",
      "704627/704627 [==============================] - 33s 46us/step - loss: 4499390055.4998 - mean_squared_error: 4499390055.4998 - val_loss: 4418783051.1018 - val_mean_squared_error: 4418783051.1018\n",
      "Epoch 14/20\n",
      "704627/704627 [==============================] - 32s 46us/step - loss: 4479699649.1007 - mean_squared_error: 4479699649.1007 - val_loss: 4461757816.7909 - val_mean_squared_error: 4461757816.7909\n",
      "Epoch 15/20\n",
      "704627/704627 [==============================] - 32s 45us/step - loss: 4440391926.2440 - mean_squared_error: 4440391926.2440 - val_loss: 4294332070.7174 - val_mean_squared_error: 4294332070.7174\n",
      "Epoch 16/20\n",
      "704627/704627 [==============================] - 32s 46us/step - loss: 4446441067.9119 - mean_squared_error: 4446441067.9119 - val_loss: 4336269941.3661 - val_mean_squared_error: 4336269941.3661\n",
      "Epoch 17/20\n",
      "704627/704627 [==============================] - 32s 45us/step - loss: 4409782370.2460 - mean_squared_error: 4409782370.2460 - val_loss: 4329375688.1857 - val_mean_squared_error: 4329375688.1857\n",
      "Epoch 18/20\n",
      "704627/704627 [==============================] - 32s 45us/step - loss: 4408947592.1664 - mean_squared_error: 4408947592.1664 - val_loss: 4383689160.4230 - val_mean_squared_error: 4383689160.4230\n",
      "Epoch 19/20\n",
      "704627/704627 [==============================] - 32s 45us/step - loss: 4412901121.5960 - mean_squared_error: 4412901121.5960 - val_loss: 4567300875.6715 - val_mean_squared_error: 4567300875.6715\n",
      "Epoch 20/20\n",
      "704627/704627 [==============================] - 32s 45us/step - loss: 4463547681.5690 - mean_squared_error: 4463547681.5690 - val_loss: 4332068903.6397 - val_mean_squared_error: 4332068903.6397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e303828>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entreno el modelo\n",
    "model_auc_neural.fit(X_train_auc, y_train_auc, validation_data=(X_test_auc,y_test_auc), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá pones el valor que da el \"mean_squared_error\" del modelo\n",
    "MSE = 4360503664.0435\n",
    "\n",
    "print(f\"RMSE: {MSE**(1/2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Modelo de redes neuronales de predicción de installs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_inst = get_df_to_train(windows, features, label_inst, features_list_class_inst)\n",
    "df_full_inst = df_full_inst.fillna(0)\n",
    "\n",
    "# Saco los tiempos máximos\n",
    "df_full_inst = df_full_inst[df_full_inst[\"label_inst\"] < 259200]\n",
    "\n",
    "# Separo en train y test\n",
    "X_train_inst, X_test_inst, y_train_inst, y_test_inst = get_train_test_split(df_full_inst, \"label_inst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el modelo\n",
    "model_inst_neural = Sequential()\n",
    "\n",
    "# Capa de entrada\n",
    "model_inst_neural.add(Dense(10, input_dim=X_train_inst.shape[1], activation='relu'))\n",
    "\n",
    "# Capa con 30 neuronas\n",
    "model_inst_neural.add(Dense(40, activation='relu'))\n",
    "\n",
    "# Dropout para controlar el overfit\n",
    "model_inst_neural.add(Dropout(0.4))\n",
    "\n",
    "# Capa con 40 neuronas\n",
    "model_inst_neural.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Dropout para controlar el overfit\n",
    "model_inst_neural.add(Dropout(0.4))\n",
    "\n",
    "# Salida del modelo\n",
    "model_inst_neural.add(Dense(1))\n",
    "\n",
    "# Compilo el modelo\n",
    "model_inst_neural.compile(optimizer ='adam', loss = 'mean_squared_error', metrics =[metrics.mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 40)                440       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                2050      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,191\n",
      "Trainable params: 3,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Veo el modelo\n",
    "model_inst_neural.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 157881 samples, validate on 67664 samples\n",
      "Epoch 1/40\n",
      "157881/157881 [==============================] - 7s 47us/step - loss: 15574353641.6966 - mean_squared_error: 15574353641.6966 - val_loss: 14116444288.8172 - val_mean_squared_error: 14116444288.8172\n",
      "Epoch 2/40\n",
      "157881/157881 [==============================] - 7s 45us/step - loss: 11459184772.2118 - mean_squared_error: 11459184772.2118 - val_loss: 9169258992.2611 - val_mean_squared_error: 9169258992.2611\n",
      "Epoch 3/40\n",
      "157881/157881 [==============================] - 7s 45us/step - loss: 9656429644.4947 - mean_squared_error: 9656429644.4947 - val_loss: 8849867309.7640 - val_mean_squared_error: 8849867309.7640\n",
      "Epoch 4/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 9305433050.9072 - mean_squared_error: 9305433050.9072 - val_loss: 8460543718.8782 - val_mean_squared_error: 8460543718.8782\n",
      "Epoch 5/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 9089139484.1893 - mean_squared_error: 9089139484.1893 - val_loss: 8530868600.5240 - val_mean_squared_error: 8530868600.5240\n",
      "Epoch 6/40\n",
      "157881/157881 [==============================] - 7s 47us/step - loss: 8806858179.1785 - mean_squared_error: 8806858179.1785 - val_loss: 8023536183.2074 - val_mean_squared_error: 8023536183.2074\n",
      "Epoch 7/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 8591343950.7177 - mean_squared_error: 8591343950.7177 - val_loss: 7887046010.4611 - val_mean_squared_error: 7887046010.4611\n",
      "Epoch 8/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 8340955021.5888 - mean_squared_error: 8340955021.5888 - val_loss: 7608512364.6593 - val_mean_squared_error: 7608512364.6593\n",
      "Epoch 9/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 7997707190.9364 - mean_squared_error: 7997707190.9364 - val_loss: 7180838748.6782 - val_mean_squared_error: 7180838748.6782\n",
      "Epoch 10/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 7648136953.0228 - mean_squared_error: 7648136953.0228 - val_loss: 6821422705.1993 - val_mean_squared_error: 6821422705.1993\n",
      "Epoch 11/40\n",
      "157881/157881 [==============================] - 8s 49us/step - loss: 7517458758.7141 - mean_squared_error: 7517458758.7141 - val_loss: 7509844940.5458 - val_mean_squared_error: 7509844940.5458\n",
      "Epoch 12/40\n",
      "157881/157881 [==============================] - 8s 49us/step - loss: 7488874327.7688 - mean_squared_error: 7488874327.7688 - val_loss: 6907669909.8227 - val_mean_squared_error: 6907669909.8227\n",
      "Epoch 13/40\n",
      "157881/157881 [==============================] - 8s 49us/step - loss: 7425906341.8087 - mean_squared_error: 7425906341.8087 - val_loss: 6791410212.5628 - val_mean_squared_error: 6791410212.5628\n",
      "Epoch 14/40\n",
      "157881/157881 [==============================] - 8s 49us/step - loss: 7299167300.9710 - mean_squared_error: 7299167300.9710 - val_loss: 6609273343.3947 - val_mean_squared_error: 6609273343.3947\n",
      "Epoch 15/40\n",
      "157881/157881 [==============================] - 8s 49us/step - loss: 7290948310.2162 - mean_squared_error: 7290948310.2162 - val_loss: 6826180568.7737 - val_mean_squared_error: 6826180568.7737\n",
      "Epoch 16/40\n",
      "157881/157881 [==============================] - 8s 52us/step - loss: 7169195905.2007 - mean_squared_error: 7169195905.2007 - val_loss: 6401089913.0083 - val_mean_squared_error: 6401089913.0083\n",
      "Epoch 17/40\n",
      "157881/157881 [==============================] - 8s 50us/step - loss: 7073845119.4625 - mean_squared_error: 7073845119.4625 - val_loss: 6295202091.4032 - val_mean_squared_error: 6295202091.4032\n",
      "Epoch 18/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 6941509976.6282 - mean_squared_error: 6941509976.6282 - val_loss: 6215008776.3537 - val_mean_squared_error: 6215008776.3537\n",
      "Epoch 19/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 6894131873.1746 - mean_squared_error: 6894131873.1746 - val_loss: 6115059471.9205 - val_mean_squared_error: 6115059471.9205\n",
      "Epoch 20/40\n",
      "157881/157881 [==============================] - 8s 50us/step - loss: 6644567124.4399 - mean_squared_error: 6644567124.4399 - val_loss: 6040671303.3095 - val_mean_squared_error: 6040671303.3095\n",
      "Epoch 21/40\n",
      "157881/157881 [==============================] - 8s 49us/step - loss: 6653846853.5531 - mean_squared_error: 6653846853.5531 - val_loss: 5989043191.4041 - val_mean_squared_error: 5989043191.4041\n",
      "Epoch 22/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 6582513224.9793 - mean_squared_error: 6582513224.9793 - val_loss: 6090523091.5677 - val_mean_squared_error: 6090523091.5677\n",
      "Epoch 23/40\n",
      "157881/157881 [==============================] - 8s 49us/step - loss: 6548968553.8888 - mean_squared_error: 6548968553.8888 - val_loss: 5973492687.4514 - val_mean_squared_error: 5973492687.4514\n",
      "Epoch 24/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 6536897600.2461 - mean_squared_error: 6536897600.2461 - val_loss: 5965603830.9198 - val_mean_squared_error: 5965603830.9198\n",
      "Epoch 25/40\n",
      "157881/157881 [==============================] - 7s 47us/step - loss: 6545521608.7564 - mean_squared_error: 6545521608.7564 - val_loss: 5970953455.2320 - val_mean_squared_error: 5970953455.2320\n",
      "Epoch 26/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 6493480486.6851 - mean_squared_error: 6493480486.6851 - val_loss: 5966642251.4259 - val_mean_squared_error: 5966642251.4259\n",
      "Epoch 27/40\n",
      "157881/157881 [==============================] - 8s 49us/step - loss: 6508577366.5089 - mean_squared_error: 6508577366.5089 - val_loss: 5960880196.1617 - val_mean_squared_error: 5960880196.1617\n",
      "Epoch 28/40\n",
      "157881/157881 [==============================] - 8s 49us/step - loss: 6482500995.8826 - mean_squared_error: 6482500995.8826 - val_loss: 6444414708.5590 - val_mean_squared_error: 6444414708.5590\n",
      "Epoch 29/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 6506219061.8232 - mean_squared_error: 6506219061.8232 - val_loss: 5960353896.2402 - val_mean_squared_error: 5960353896.2402\n",
      "Epoch 30/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 6476963209.9275 - mean_squared_error: 6476963209.9275 - val_loss: 5970028817.7366 - val_mean_squared_error: 5970028817.7366\n",
      "Epoch 31/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 6453983268.8431 - mean_squared_error: 6453983268.8431 - val_loss: 5961028098.7846 - val_mean_squared_error: 5961028098.7846\n",
      "Epoch 32/40\n",
      "157881/157881 [==============================] - 7s 45us/step - loss: 6451385946.1994 - mean_squared_error: 6451385946.1994 - val_loss: 5950838955.9177 - val_mean_squared_error: 5950838955.9177\n",
      "Epoch 33/40\n",
      "157881/157881 [==============================] - 7s 47us/step - loss: 6452489795.6576 - mean_squared_error: 6452489795.6576 - val_loss: 5969013402.9681 - val_mean_squared_error: 5969013402.9681\n",
      "Epoch 34/40\n",
      "157881/157881 [==============================] - 7s 47us/step - loss: 6435841860.1457 - mean_squared_error: 6435841860.1457 - val_loss: 5982659622.0156 - val_mean_squared_error: 5982659622.0156\n",
      "Epoch 35/40\n",
      "157881/157881 [==============================] - 7s 47us/step - loss: 6441731018.0081 - mean_squared_error: 6441731018.0081 - val_loss: 5965058949.7205 - val_mean_squared_error: 5965058949.7205\n",
      "Epoch 36/40\n",
      "157881/157881 [==============================] - 7s 45us/step - loss: 6431921070.4171 - mean_squared_error: 6431921070.4171 - val_loss: 5964905826.4895 - val_mean_squared_error: 5964905826.4895\n",
      "Epoch 37/40\n",
      "157881/157881 [==============================] - 7s 47us/step - loss: 6421892099.9402 - mean_squared_error: 6421892099.9402 - val_loss: 5970719504.7680 - val_mean_squared_error: 5970719504.7680\n",
      "Epoch 38/40\n",
      "157881/157881 [==============================] - 8s 48us/step - loss: 6424468598.7081 - mean_squared_error: 6424468598.7081 - val_loss: 5979334372.5779 - val_mean_squared_error: 5979334372.5779\n",
      "Epoch 39/40\n",
      "157881/157881 [==============================] - 7s 46us/step - loss: 6446773975.8377 - mean_squared_error: 6446773975.8377 - val_loss: 5952943342.2634 - val_mean_squared_error: 5952943342.2634\n",
      "Epoch 40/40\n",
      "157881/157881 [==============================] - 7s 47us/step - loss: 6440201202.9796 - mean_squared_error: 6440201202.9796 - val_loss: 5957715324.6403 - val_mean_squared_error: 5957715324.6403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13668fe80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entreno el modelo\n",
    "model_inst_neural.fit(X_train_inst, y_train_inst, validation_data=(X_test_inst,y_test_inst), epochs=40, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá pones el valor que da el \"mean_squared_error\" del modelo\n",
    "MSE = 6556917330.7763\n",
    "\n",
    "print(f\"RMSE: {MSE**(1/2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***XGBoost***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Modelo de XGBoost de predicción de auctions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = get_df_to_train(windows, features, label_auc, features_list_class_auc)\n",
    "\n",
    "df_full = df_full.sample(int(len(df_full)))\n",
    "\n",
    "#df_full = balance(df_full, \"label_auc\", 0, 259200)\n",
    "\n",
    "df_full = df_full.loc[df_full[\"label_auc\"] != 259200]\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(df_full, \"label_auc\", 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auc = xgb.XGBRegressor(   \n",
    "    gamma=0.1, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=3,  \n",
    "    n_estimators=500,\n",
    "    n_jobs=2,  \n",
    "    objective='reg:linear',   \n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 63387.104967\n",
      "CPU times: user 15min 9s, sys: 1.08 s, total: 15min 10s\n",
      "Wall time: 15min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_auc.fit(X_train, y_train, eval_metric='rmse')\n",
    "#cv = xgb.cv(params, xg_train, 5000, nfold=n_folds, early_stopping_rounds=early_stopping, verbose_eval=1)\n",
    "prediction = model_auc.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### ***Mejor modelo de auctions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE: 63345.641573\n",
    "CPU times: user 25min 48s, sys: 8.65 s, total: 25min 57s\n",
    "Wall time: 26min 8s\n",
    "    \n",
    "model_auc = xgb.XGBRegressor(\n",
    "    base_score=0.5, \n",
    "    booster='gbtree', \n",
    "    colsample_bylevel=1,\n",
    "    colsample_bytree=1, \n",
    "    gamma=0.1, \n",
    "    learning_rate=0.1, \n",
    "    max_delta_step=0,\n",
    "    max_depth=4, \n",
    "    min_child_weight=1, \n",
    "    missing=None, \n",
    "    n_estimators=600,\n",
    "    n_jobs=1, \n",
    "    nthread=None, \n",
    "    objective='reg:linear', \n",
    "    random_state=0,\n",
    "    reg_alpha=0, \n",
    "    reg_lambda=1, \n",
    "    scale_pos_weight=1, \n",
    "    seed=None,\n",
    "    silent=True, \n",
    "    subsample=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_importance(model_auc, height=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance, plot_tree\n",
    "_ = plot_importance(model_auc, height=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ***Modelo de XGBoost de predicción de installs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_installs = get_df_to_train(windows, features, label_inst, features_list_class_inst)\n",
    "\n",
    "df_full_installs = df_full_installs.sample(int(len(df_full_installs)))\n",
    "\n",
    "#df_full_installs = balance(df_full_installs, \"label_inst\", 1, 259200)\n",
    "df_full_installs = df_full_installs[df_full_installs[\"label_inst\"] != 259200]\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(df_full_installs, \"label_inst\", 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inst = xgb.XGBRegressor(\n",
    "    learning_rate = 0.1,\n",
    "    n_estimators=700,\n",
    "    max_dept=5,\n",
    "    gamma=0.1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:54:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE: 76838.972833\n",
      "CPU times: user 4min 49s, sys: 240 ms, total: 4min 50s\n",
      "Wall time: 4min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_inst.fit(X_train, y_train, eval_metric='rmse', verbose=True)\n",
    "\n",
    "prediction = model_inst.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance, plot_tree\n",
    "_ = plot_importance(model_inst, height=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### ***Mejor modelo de installs***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "RMSE: 76768.119164\n",
    "CPU times: user 5min 39s, sys: 2 s, total: 5min 41s\n",
    "Wall time: 5min 44s\n",
    "\n",
    "model_inst = xgb.XGBRegressor(\n",
    "    learning_rate = 0.1,\n",
    "    n_estimators=700,\n",
    "    max_dept=5,\n",
    "    gamma=0.1,\n",
    "    n_jobs=-1\n",
    ")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción auctions XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auctions = model_auc.predict(select_features(features_to_predict, features_list_class_auc))\n",
    "df_preds_auctions = pd.DataFrame({'ref_hash' : features_to_predict.index, 'obj' : pred_auctions})\n",
    "#df_preds_auctions.to_csv(\"auctions_predictions.csv\", index=False) #persistimos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción auctions Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auctions_neural = model_auc_neural.predict(select_features(features_to_predict, features_list_class_auc).fillna(0))\n",
    "pred_auctions_neural = np.array(pred_auctions_neural).flatten()\n",
    "df_preds_auctions_neural = pd.DataFrame({'ref_hash' : features_to_predict.index, 'obj' : pred_auctions_neural})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción installs XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_installs = model_inst.predict(select_features(features_to_predict, features_list_class_inst))\n",
    "df_preds_installs = pd.DataFrame({'ref_hash' : features_to_predict.index, 'obj' : pred_installs})\n",
    "#df_preds_installs.to_csv(\"installs_predictions.csv\", index=False) #persistimos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción installs Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_installs_neural = model_inst_neural.predict(select_features(features_to_predict, features_list_class_inst).fillna(0))\n",
    "pred_installs_neural = np.array(pred_installs_neural).flatten()\n",
    "df_preds_installs_neural = pd.DataFrame({'ref_hash' : features_to_predict.index, 'obj' : pred_installs_neural})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clas_inst = model_class_inst.predict(features_to_predict)\n",
    "\n",
    "df_preds_installs = pd.DataFrame({\"ref_hash\":features_to_predict.index,\"obj\":pred_clas_inst})\n",
    "ref_not_to_predict = []#df_preds_installs.loc[df_preds_installs[\"obj\"] == 1][\"ref_hash\"].unique()\n",
    "\n",
    "df_to_predict = features_to_predict.drop(index=ref_to_predict)\n",
    "\n",
    "pred_installs = model_inst.predict(df_to_predict.reset_index(drop=True))\n",
    "\n",
    "df_pred_value = pd.DataFrame({\"ref_hash\":df_to_predict.index,\"value\":pred_installs})\n",
    "\n",
    "df_preds_installs = df_preds_installs.merge(df_pred_value,left_on=\"ref_hash\",right_on=\"ref_hash\",how=\"left\")\n",
    "df_preds_installs[\"obj\"] = df_preds_installs[\"value\"]\n",
    "del df_preds_installs[\"value\"]\n",
    "df_preds_installs = df_preds_installs.fillna(259200)\n",
    "\n",
    "df_preds_installs.to_csv(\"installs_predictions.csv\", index=False) #persistimos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = get_df_to_train(windows, features, label_auc, features_list_class_auc)\n",
    "df_full = df_full.sample(int(len(df_full)*0.1))\n",
    "df_full = df_full[df_full[\"label_auc\"] != 259200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_depth and min_child_weight tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring= 'neg_mean_squared_error', n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(df_full[features_list_class_auc],df_full['label_auc'])\n",
    "#gsearch1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch1.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Refinamos la búsqueda entre valores acotados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth': [3,4,5],\n",
    " 'min_child_weight': [3,4,5]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBRegressor(learning_rate =0.01, n_estimators=1000, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring= 'neg_mean_squared_error', n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(df_full[features_list_class_auc],df_full['label_auc'])\n",
    "#gsearch2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch2.best_params_  #los mejores parámetros son max_depth 4 y min child_weight 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch2.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and n_estimators tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    "    'n_estimators' : [100,200,500, 1000],\n",
    "    'learning_rate' : [0.1, 0.05, 0.01]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBRegressor(learning_rate =0.1, n_estimators=140, max_depth=3,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test3, scoring= 'neg_mean_squared_error', n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(df_full[features_list_class_auc],df_full['label_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch3.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBRegressor(learning_rate =0.1, n_estimators=200, max_depth=4,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test4, scoring= 'neg_mean_squared_error', n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(df_full[features_list_class_auc],df_full['label_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch4.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample and colsample_bytree tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBRegressor( learning_rate = 0.1, n_estimators=200, max_depth=4,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(df_full[features_list_class_auc],df_full['label_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch5.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBRegressor( learning_rate = 0.1, n_estimators=200, max_depth=4,\n",
    " min_child_weight=3, gamma=0, subsample=0.9, colsample_bytree=0.7,\n",
    " objective= 'reg:squarederror', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(df_full[features_list_class_auc],df_full['label_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(gsearch6.best_score_ * (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df(df, name):\n",
    "    df.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las predicciones tendrán seteadas como índice los ref_hash para no perder la referencia\n",
    "No es necesario filtrar los ref_hash y quedarnos solo con los target en las predicciones que obtenemos ya que de eso\n",
    "se encarga la función "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"target_competencia_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_preds_installs = pd.read_csv(\"installs_predictions.csv\")\n",
    "#df_preds_auctions = pd.read_csv(\"auctions_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit_df(auctions_predictions, installs_predictions, target):\n",
    "    \n",
    "    target = target.set_index('ref_hash')\n",
    "    \n",
    "    auc = auctions_predictions.reset_index()\n",
    "    auc.columns = ['ref_hash','obj']\n",
    "    auc['ref_hash'] = auc['ref_hash'].astype(str) + \"_st\"\n",
    "    auc = auc.set_index('ref_hash')\n",
    "    \n",
    "    ins = installs_predictions.reset_index()\n",
    "    ins.columns = ['ref_hash','obj']\n",
    "    ins['ref_hash'] = ins['ref_hash'].astype(str) + \"_sc\"\n",
    "    ins = ins.set_index('ref_hash')\n",
    "    \n",
    "    frames = [ins,auc]\n",
    "    submit_result = pd.concat(frames).reset_index()\n",
    "    target_list = target.reset_index('ref_hash')['ref_hash'].tolist()\n",
    "    return submit_result.loc[submit_result['ref_hash'].isin(target_list)].sort_values(by = 'ref_hash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_sub = create_submit_df(df_preds_auctions.set_index('ref_hash'), \\\n",
    "                              df_preds_installs.set_index('ref_hash'), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df(kaggle_sub, \"submit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_sub_neural = create_submit_df(df_preds_auctions_neural.set_index('ref_hash'), \\\n",
    "                              df_preds_installs_neural.set_index('ref_hash'), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df(kaggle_sub_neural, \"submit_neural.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_df = kaggle_sub.merge(kaggle_sub_neural, on=\"ref_hash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_df[\"obj\"] = (ensamble_df[\"obj_x\"] + ensamble_df[\"obj_y\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_kaggle = ensamble_df[[\"ref_hash\", \"obj\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df(ensamble_kaggle, \"submit_ensamble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
